spring.application.name=java-chat

# Spring Profile (dev, prod)
spring.profiles.active=${SPRING_PROFILE:dev}

# HTTP server (restricted to 8085-8090 by PortInitializer)
server.port=${PORT:8085}

# Memory-sensitive defaults for 512MB container budgets (no behavior change)
spring.main.lazy-initialization=${SPRING_MAIN_LAZY_INITIALIZATION:true}
spring.http.codecs.max-in-memory-size=${SPRING_HTTP_CODECS_MAX_IN_MEMORY_SIZE:1MB}

# Spring AI - GitHub Models Configuration (Primary)
# CRITICAL: GitHub Models endpoint is https://models.github.ai/inference
# DO NOT USE: models.inference.ai.azure.com (this is a hallucinated URL)
# DO NOT USE: Any azure.com domain (we don't have Azure instances)
# CORRECT ENDPOINT: https://models.github.ai/inference (as per GitHub Models docs)
# Reference: https://docs.github.com/en/github-models/prototyping-with-ai-models
spring.ai.openai.base-url=${OPENAI_BASE_URL:https://models.github.ai/inference}
spring.ai.openai.chat.options.model=${OPENAI_MODEL:gpt-5}
spring.ai.openai.chat.options.temperature=${OPENAI_TEMPERATURE:0.7}
# Use GitHub token for GitHub Models, or OpenAI API key for fallback
# To avoid rate limits, set OPENAI_API_KEY in addition to GITHUB_TOKEN
spring.ai.openai.api-key=${GITHUB_TOKEN:${OPENAI_API_KEY:dummy-key-for-startup}}
spring.ai.openai.chat.api-key=${GITHUB_TOKEN:${OPENAI_API_KEY:dummy-key-for-startup}}

# Rate limiting and retry configuration
# More conservative defaults to handle GitHub Models API rate limits
spring.ai.retry.max-attempts=${AI_RETRY_MAX_ATTEMPTS:5}
spring.ai.retry.backoff.initial-interval=${AI_RETRY_INITIAL_INTERVAL:2000}
spring.ai.retry.backoff.max-interval=${AI_RETRY_MAX_INTERVAL:30000}
spring.ai.retry.backoff.multiplier=${AI_RETRY_MULTIPLIER:2}

# HTTP client timeout configuration for GitHub Models API
# GitHub Models can be slower than OpenAI, so increase timeouts
# Note: Spring AI doesn't expose timeout properties directly
# Timeouts are configured via WebClient/RestClient beans in AiConfig

# Embeddings model (GitHub Models compatible)
# NOTE: GitHub Models doesn't support embeddings API yet
# Use OpenAI directly for embeddings or disable vector search
spring.ai.openai.embedding.options.model=${GITHUB_MODELS_EMBED_MODEL:text-embedding-3-small}
spring.ai.openai.embedding.base-url=${OPENAI_EMBEDDING_BASE_URL:https://api.openai.com/v1}
spring.ai.openai.embedding.api-key=${OPENAI_API_KEY:dummy-key-for-startup}
# Toggle for local embeddings (when true, uses LocalEmbeddingModel)
# Set to true to use your local embedding server
app.local-embedding.enabled=${APP_LOCAL_EMBEDDING_ENABLED:false}
# Local embedding server configuration - set default to allowed range (8085-8090)
app.local-embedding.server-url=${LOCAL_EMBEDDING_SERVER_URL:http://127.0.0.1:8088}
# Support both APP_LOCAL_EMBEDDING_MODEL and LOCAL_EMBEDDING_MODEL_NAME env vars
app.local-embedding.model=${APP_LOCAL_EMBEDDING_MODEL:${LOCAL_EMBEDDING_MODEL_NAME:text-embedding-qwen3-embedding-8b}}
app.local-embedding.dimensions=${APP_LOCAL_EMBEDDING_DIMENSIONS:4096}
# Enable hash-based fallback when embedding services fail (provides limited semantic search)
app.local-embedding.use-hash-when-disabled=${APP_LOCAL_EMBEDDING_USE_HASH_WHEN_DISABLED:true}

# Remote embedding provider (OpenAI-compatible, e.g., Novita)
app.remote-embedding.server-url=${REMOTE_EMBEDDING_SERVER_URL:}
app.remote-embedding.model=${REMOTE_EMBEDDING_MODEL_NAME:text-embedding-3-small}
app.remote-embedding.api-key=${REMOTE_EMBEDDING_API_KEY:}
app.remote-embedding.dimensions=${REMOTE_EMBEDDING_DIMENSIONS:4096}

# Qdrant configuration (defaults to local Docker)
spring.ai.vectorstore.qdrant.host=${QDRANT_HOST:localhost}
spring.ai.vectorstore.qdrant.port=${QDRANT_PORT:6334}
spring.ai.vectorstore.qdrant.api-key=${QDRANT_API_KEY:}
spring.ai.vectorstore.qdrant.use-tls=${QDRANT_SSL:false}
spring.ai.vectorstore.qdrant.collection-name=${QDRANT_COLLECTION:java-chat}
spring.ai.vectorstore.qdrant.initialize-schema=${QDRANT_INIT_SCHEMA:true}
# App-level toggle to skip payload index ensure step at startup (useful when debugging startups)
# Note: Spring AI Qdrant doesn't have a check-compatibility property
# Warnings about version compatibility are handled by logging configuration

# Retrieval defaults (match AppProperties.Rag)
app.rag.chunk-max-tokens=${RAG_CHUNK_MAX_TOKENS:900}
app.rag.chunk-overlap-tokens=${RAG_CHUNK_OVERLAP_TOKENS:150}
app.rag.search-top-k=${RAG_TOP_K:12}
app.rag.search-return-k=${RAG_RETURN_K:6}
app.rag.search-citations=${RAG_CITATIONS_K:3}
app.rag.search-mmr-lambda=${RAG_MMR_LAMBDA:0.5}

# Java 24 docs crawl root (immutable snapshot target)
app.docs.root-url=${DOCS_ROOT_URL:https://docs.oracle.com/en/java/javase/24/}
app.docs.jdk-version=${DOCS_JDK_VERSION:24}
app.docs.snapshot-dir=${DOCS_SNAPSHOT_DIR:data/snapshots}
app.docs.parsed-dir=${DOCS_PARSED_DIR:data/parsed}
app.docs.index-dir=${DOCS_INDEX_DIR:data/index}

# Skip Qdrant payload index ensure on boot in constrained environments
app.qdrant.ensure-payload-indexes=${APP_QDRANT_ENSURE_PAYLOAD_INDEXES:false}

# Static Resources Configuration
# Enable static resource handling with proper cache control
spring.web.resources.static-locations=classpath:/static/,classpath:/public/
spring.web.resources.cache.period=3600
spring.web.resources.chain.strategy.content.enabled=true
spring.web.resources.chain.strategy.content.paths=/**

# Actuator
management.endpoints.web.exposure.include=health,info,metrics
# Reduce Qdrant client warning verbosity via logging
logging.level.io.qdrant=ERROR
# Suppress PDFBox font mapping warnings (these are harmless)
logging.level.org.apache.pdfbox.pdmodel.font=ERROR

# Spring Security - configuration
# Keep UserDetailsService auto-config disabled to avoid default user + password logging
# but allow SecurityAutoConfiguration so HttpSecurity is available for our filters
# Exclude OpenAI models that require API keys to prevent startup failures
spring.autoconfigure.exclude=org.springframework.boot.autoconfigure.security.servlet.UserDetailsServiceAutoConfiguration,org.springframework.ai.model.openai.autoconfigure.OpenAiAudioSpeechAutoConfiguration,org.springframework.ai.model.openai.autoconfigure.OpenAiAudioTranscriptionAutoConfiguration,org.springframework.ai.model.openai.autoconfigure.OpenAiImageAutoConfiguration,org.springframework.ai.model.openai.autoconfigure.OpenAiModerationAutoConfiguration
